
R version 3.6.3 (2020-02-29) -- "Holding the Windsock"
Copyright (C) 2020 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> # Objective: running a joint model combining NDDM and RIM to estimate all interactions at the same time. 
> # 
> # Run in Terminal: 
> #   
> #   R CMD BATCH '--args 0' model.R model/0_model_script.Rout
> # 
> # substituting '0' for the comm number (0, 1, 2, or 3) 
> # 
> # This calls up model.R, which runs joint_model.stan. 
> # results got to model/output, /transformed and /validation
> 
> 
> # Run the joint model: 
> # 1. Estimate inferrable interactions with NDDM 
> # 2. Estimate response and effect interactions when non-inferrable
> 
> # Then: 
> # 3. Extract the intrinsic growth rates 
> # 5. Scale the interactions into per-capita growth rates
> 
> # PRELUDE
> #-------
> Sys.time()
[1] "2022-01-24 17:12:43 AEST"
> 
> # Get arguments from bash script
> #!/usr/bin/env Rscript
> args = commandArgs(trailingOnly=TRUE)
> # take comm name as an argument from bash
> if (length(args)==0) {
+   stop("At least one argument must be supplied (input file).n", call.=FALSE)
+ } 
> if (length(args)>1) {
+   stop("Model can only be run on 1 comm at a time.n", call.=FALSE)
+ }
> comm <- args[1]
> 
> # set up R environment
> library(rstan)
Loading required package: StanHeaders
Loading required package: ggplot2
rstan (Version 2.21.2, GitRev: 2e1f913d3ca3)
For execution on a local, multicore CPU with excess RAM we recommend calling
options(mc.cores = parallel::detectCores()).
To avoid recompilation of unchanged Stan programs, we recommend calling
rstan_options(auto_write = TRUE)
> rstan_options(auto_write = TRUE)
> options(mc.cores = parallel::detectCores()) 
> 
> library(rethinking)
Loading required package: parallel
rethinking (Version 1.59)
> library(reshape2)
> library(here)
here() starts at /home/uqmbimle/Dropbox/Work/Projects/2020_Methods_for_compnet
> 
> setwd(here('2.case_study/'))
> 
> source('../1.code/data_prep.R')
> source('functions/stan_modelcheck_rem.R')
> source('functions/scale_interactions.R')
> 
> # Load, verify & prepare data
> #----------------------------
> fecundities <- read.csv(paste0('data/fecundities', comm, '.csv'), stringsAsFactors = F)
> 
> # Keep note of how focals and neighbours are indexed
> key_speciesID <- unlist(read.csv(paste0('data/key_speciesID', comm, '.csv'), stringsAsFactors = F))
> key_neighbourID <- unlist(read.csv(paste0('data/key_neighbourID', comm, '.csv'), stringsAsFactors = F))
> 
> # ensure neighbours are linearly independent across the whole dataset
> N_all <- apply(fecundities[ , 5:dim(fecundities)[2]], c(1,2), as.numeric)
> X_all <- cbind(model.matrix(~as.factor(fecundities$focal)), N_all)
> R_all <- pracma::rref(X_all)
> Z_all <- t(R_all) %*% R_all
> indep <- sapply(seq(1, dim(Z_all)[1], 1), function(k){ 
+   ifelse(Z_all[k, k] == 1 & sum(Z_all[k, -k]) == 0, 1, 0)
+ }) #
> all(indep == 1) # if TRUE then neighbours are linearly independent and we can continue
[1] TRUE
> if(!all(indep == 1)) message('WARNING neighbours are not linearly independent') 
> 
> # transform data into format required by STAN
> stan.data <- data_prep(perform = 'seeds', focal = 'focal', 
+                        nonNcols = 4, df = fecundities)
> 
> 
> message(paste0('Community selected: ', comm))
Community selected: 0
> message(paste0('Fecundity data dimensions = ', dim(fecundities)[1], ', ', dim(fecundities)[2]))
Fecundity data dimensions = 5736, 56
> message(paste0('Number of focals = ', length(key_speciesID)))
Number of focals = 22
> message(paste0('Number of neighbours = ', length(key_neighbourID)))
Number of neighbours = 52
> message(paste0('Proportion of inferrable interactions = ', sum(stan.data$Q)/(stan.data$S*stan.data$K)))
Proportion of inferrable interactions = 0.567307692307692
> 
> #--------------------------------------------------
> # Estimate interactions with a joint NDD*RI model |
> #--------------------------------------------------
> 
> fit <- stan(file = '../1.code/joint_model.stan',
+             data =  stan.data,               # named list of data
+             chains = 1,
+             warmup = 5000,          # number of warmup iterations per chain
+             iter = 10000,            # total number of iterations per chain
+             refresh = 100,         # show progress every 'refresh' iterations
+             control = list(max_treedepth = 10)
+ )

SAMPLING FOR MODEL 'joint_model' NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 0.017266 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 172.66 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 10000 [  0%]  (Warmup)
Chain 1: Iteration:  100 / 10000 [  1%]  (Warmup)
Chain 1: Iteration:  200 / 10000 [  2%]  (Warmup)
Chain 1: Iteration:  300 / 10000 [  3%]  (Warmup)
Chain 1: Iteration:  400 / 10000 [  4%]  (Warmup)
Chain 1: Iteration:  500 / 10000 [  5%]  (Warmup)
Chain 1: Iteration:  600 / 10000 [  6%]  (Warmup)
Chain 1: Iteration:  700 / 10000 [  7%]  (Warmup)
Chain 1: Iteration:  800 / 10000 [  8%]  (Warmup)
Chain 1: Iteration:  900 / 10000 [  9%]  (Warmup)
Chain 1: Iteration: 1000 / 10000 [ 10%]  (Warmup)
Chain 1: Iteration: 1100 / 10000 [ 11%]  (Warmup)
Chain 1: Iteration: 1200 / 10000 [ 12%]  (Warmup)
Chain 1: Iteration: 1300 / 10000 [ 13%]  (Warmup)
Chain 1: Iteration: 1400 / 10000 [ 14%]  (Warmup)
Chain 1: Iteration: 1500 / 10000 [ 15%]  (Warmup)
Chain 1: Iteration: 1600 / 10000 [ 16%]  (Warmup)
Chain 1: Iteration: 1700 / 10000 [ 17%]  (Warmup)
Chain 1: Iteration: 1800 / 10000 [ 18%]  (Warmup)
Chain 1: Iteration: 1900 / 10000 [ 19%]  (Warmup)
Chain 1: Iteration: 2000 / 10000 [ 20%]  (Warmup)
Chain 1: Iteration: 2100 / 10000 [ 21%]  (Warmup)
Chain 1: Iteration: 2200 / 10000 [ 22%]  (Warmup)
Chain 1: Iteration: 2300 / 10000 [ 23%]  (Warmup)
Chain 1: Iteration: 2400 / 10000 [ 24%]  (Warmup)
Chain 1: Iteration: 2500 / 10000 [ 25%]  (Warmup)
Chain 1: Iteration: 2600 / 10000 [ 26%]  (Warmup)
Chain 1: Iteration: 2700 / 10000 [ 27%]  (Warmup)
Chain 1: Iteration: 2800 / 10000 [ 28%]  (Warmup)
Chain 1: Iteration: 2900 / 10000 [ 29%]  (Warmup)
Chain 1: Iteration: 3000 / 10000 [ 30%]  (Warmup)
Chain 1: Iteration: 3100 / 10000 [ 31%]  (Warmup)
Chain 1: Iteration: 3200 / 10000 [ 32%]  (Warmup)
Chain 1: Iteration: 3300 / 10000 [ 33%]  (Warmup)
Chain 1: Iteration: 3400 / 10000 [ 34%]  (Warmup)
Chain 1: Iteration: 3500 / 10000 [ 35%]  (Warmup)
Chain 1: Iteration: 3600 / 10000 [ 36%]  (Warmup)
Chain 1: Iteration: 3700 / 10000 [ 37%]  (Warmup)
Chain 1: Iteration: 3800 / 10000 [ 38%]  (Warmup)
Chain 1: Iteration: 3900 / 10000 [ 39%]  (Warmup)
Chain 1: Iteration: 4000 / 10000 [ 40%]  (Warmup)
Chain 1: Iteration: 4100 / 10000 [ 41%]  (Warmup)
Chain 1: Iteration: 4200 / 10000 [ 42%]  (Warmup)
Chain 1: Iteration: 4300 / 10000 [ 43%]  (Warmup)
Chain 1: Iteration: 4400 / 10000 [ 44%]  (Warmup)
Chain 1: Iteration: 4500 / 10000 [ 45%]  (Warmup)
Chain 1: Iteration: 4600 / 10000 [ 46%]  (Warmup)
Chain 1: Iteration: 4700 / 10000 [ 47%]  (Warmup)
Chain 1: Iteration: 4800 / 10000 [ 48%]  (Warmup)
Chain 1: Iteration: 4900 / 10000 [ 49%]  (Warmup)
Chain 1: Iteration: 5000 / 10000 [ 50%]  (Warmup)
Chain 1: Iteration: 5001 / 10000 [ 50%]  (Sampling)
Chain 1: Iteration: 5100 / 10000 [ 51%]  (Sampling)
Chain 1: Iteration: 5200 / 10000 [ 52%]  (Sampling)
Chain 1: Iteration: 5300 / 10000 [ 53%]  (Sampling)
Chain 1: Iteration: 5400 / 10000 [ 54%]  (Sampling)
Chain 1: Iteration: 5500 / 10000 [ 55%]  (Sampling)
Chain 1: Iteration: 5600 / 10000 [ 56%]  (Sampling)
Chain 1: Iteration: 5700 / 10000 [ 57%]  (Sampling)
Chain 1: Iteration: 5800 / 10000 [ 58%]  (Sampling)
Chain 1: Iteration: 5900 / 10000 [ 59%]  (Sampling)
Chain 1: Iteration: 6000 / 10000 [ 60%]  (Sampling)
Chain 1: Iteration: 6100 / 10000 [ 61%]  (Sampling)
Chain 1: Iteration: 6200 / 10000 [ 62%]  (Sampling)
Chain 1: Iteration: 6300 / 10000 [ 63%]  (Sampling)
Chain 1: Iteration: 6400 / 10000 [ 64%]  (Sampling)
Chain 1: Iteration: 6500 / 10000 [ 65%]  (Sampling)
Chain 1: Iteration: 6600 / 10000 [ 66%]  (Sampling)
Chain 1: Iteration: 6700 / 10000 [ 67%]  (Sampling)
Chain 1: Iteration: 6800 / 10000 [ 68%]  (Sampling)
Chain 1: Iteration: 6900 / 10000 [ 69%]  (Sampling)
Chain 1: Iteration: 7000 / 10000 [ 70%]  (Sampling)
Chain 1: Iteration: 7100 / 10000 [ 71%]  (Sampling)
Chain 1: Iteration: 7200 / 10000 [ 72%]  (Sampling)
Chain 1: Iteration: 7300 / 10000 [ 73%]  (Sampling)
Chain 1: Iteration: 7400 / 10000 [ 74%]  (Sampling)
Chain 1: Iteration: 7500 / 10000 [ 75%]  (Sampling)
Chain 1: Iteration: 7600 / 10000 [ 76%]  (Sampling)
Chain 1: Iteration: 7700 / 10000 [ 77%]  (Sampling)
Chain 1: Iteration: 7800 / 10000 [ 78%]  (Sampling)
Chain 1: Iteration: 7900 / 10000 [ 79%]  (Sampling)
Chain 1: Iteration: 8000 / 10000 [ 80%]  (Sampling)
Chain 1: Iteration: 8100 / 10000 [ 81%]  (Sampling)
Chain 1: Iteration: 8200 / 10000 [ 82%]  (Sampling)
Chain 1: Iteration: 8300 / 10000 [ 83%]  (Sampling)
Chain 1: Iteration: 8400 / 10000 [ 84%]  (Sampling)
Chain 1: Iteration: 8500 / 10000 [ 85%]  (Sampling)
Chain 1: Iteration: 8600 / 10000 [ 86%]  (Sampling)
Chain 1: Iteration: 8700 / 10000 [ 87%]  (Sampling)
Chain 1: Iteration: 8800 / 10000 [ 88%]  (Sampling)
Chain 1: Iteration: 8900 / 10000 [ 89%]  (Sampling)
Chain 1: Iteration: 9000 / 10000 [ 90%]  (Sampling)
Chain 1: Iteration: 9100 / 10000 [ 91%]  (Sampling)
Chain 1: Iteration: 9200 / 10000 [ 92%]  (Sampling)
Chain 1: Iteration: 9300 / 10000 [ 93%]  (Sampling)
Chain 1: Iteration: 9400 / 10000 [ 94%]  (Sampling)
Chain 1: Iteration: 9500 / 10000 [ 95%]  (Sampling)
Chain 1: Iteration: 9600 / 10000 [ 96%]  (Sampling)
Chain 1: Iteration: 9700 / 10000 [ 97%]  (Sampling)
Chain 1: Iteration: 9800 / 10000 [ 98%]  (Sampling)
Chain 1: Iteration: 9900 / 10000 [ 99%]  (Sampling)
Chain 1: Iteration: 10000 / 10000 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 2368.02 seconds (Warm-up)
Chain 1:                2726.05 seconds (Sampling)
Chain 1:                5094.07 seconds (Total)
Chain 1: 
> 
> # parameters of interest
> param.vec <- fit@model_pars[!fit@model_pars %in% c('response1', 'responseSm1', 'lp__')]
> 
> 
> # Raw output
> #------------
> save(fit, file = paste0('model/output/model_fit.Rdata')) # model fit
> # Save the 'raw' draws from the posterior
> joint.post.draws <- extract.samples(fit)
> save(joint.post.draws, file = paste0('model/output/post_draws.Rdata'))
> 
> # Save mean, 10% and 90% quantiles for each parameter, as well as n_eff and Rhat
> fit_sum <- summary(fit, pars = param.vec, probs = c(0.1, 0.9))$summary
> write.csv(fit_sum, file = paste0('model/output/summary_of_draws.csv'), row.names = T)
> 
> # Save the logarithm of the (unnormalized) posterior density (lp__)
> log_post <- unlist(extract(fit, 'lp__'))
> write.csv(log_post, file = paste0('model/output/log_post.csv'), row.names = F)
> 
> # Validation
> #------------
> # Get Geweke statistics
> matrix_of_draws <- as.matrix(fit)
> gew <- coda::geweke.diag(matrix_of_draws)
> write.csv(gew$z, 'model/validation/gew_stats.csv')
> # get adjusted values (see boral() package)
> gew.pvals <- 2*pnorm(abs(unlist(gew$z)), lower.tail = FALSE)
> adj.gew <- p.adjust(gew.pvals, method = "holm")
> write.csv(adj.gew, 'model/validation/gew_stats_holmadjust.csv')
> print(paste0('Range of p-values for chain convergence: ', min(na.omit(adj.gew)), ' to ',  max(na.omit(adj.gew))))
[1] "Range of p-values for chain convergence: 0.0327157823342563 to 1"
> 
> png('model/validation/geweke_dist.png', width = 500, height = 500)
> plot(density(na.omit(gew$z)))
> lines(density(rnorm(10000)), col = 'red')
> abline(v = -2, lty = 2)
> abline(v = 2, lty = 2)
> dev.off()
null device 
          1 
> 
> 
> # Diagnostics
> stan_diagnostic(fit, 'model/validation/')

Divergences:
0 of 5000 iterations ended with a divergence.

Tree depth:
0 of 5000 iterations saturated the maximum tree depth of 10.

Energy:
E-BFMI indicated no pathological behavior.
0 of 5000 iterations saturated the maximum tree depth of 10.
E-BFMI indicated no pathological behavior.
0 of 5000 iterations ended with a divergence.
[1] "rhat range: "      "0.999799979996296" "1.00531821483615" 
[1] "n_eff range: "   "876.43526194306" "13782.25763414" 
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
null device 
          1 
> # Traceplots and posterior uncertainty intervals
> stan_model_check(fit, 'model/validation/', params = param.vec)
ci_level: 0.8 (80% intervals)
outer_level: 0.95 (95% intervals)
ci_level: 0.8 (80% intervals)
outer_level: 0.95 (95% intervals)
ci_level: 0.8 (80% intervals)
outer_level: 0.95 (95% intervals)
ci_level: 0.8 (80% intervals)
outer_level: 0.95 (95% intervals)
ci_level: 0.8 (80% intervals)
outer_level: 0.95 (95% intervals)
Error in png(paste0(results_folder, "/tplot_", x, ".png"), width = 800,  : 
  unable to start device 'png'
Calls: stan_model_check -> sapply -> lapply -> FUN -> png
In addition: Warning message:
In png(paste0(results_folder, "/tplot_", x, ".png"), width = 800,  :
  cairo error 'invalid value (typically too big) for the size of the input (surface, pattern, etc.)'
Execution halted
